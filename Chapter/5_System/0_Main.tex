\chapter{\todo{System implementation}}\label{5_systemIntegration}
The following chapter discusses the implementation of an interactive slackline learning system with real-time feedback based on the prior conceptual elaboration.
%A certain freedom of movement of the user is necessary to be able to practice slackline exercises appropriately.
Like already discussed in section~\textit{\nameref{trackingTechnologie}} the low-cost tracking camera Microsoft Kinect v2 will be used as tracking device.
%Therefore, like already discussed in section~\textit{\nameref{trackingTechnologie}}, the low-cost tracking camera Microsoft Kinect v2 will be used as tracking device. 
Before going into detail with the actual implementation, section~\textit{\nameref{5_1_systemSetup}} discusses the general system architecture including a comparison of the Kinects' tracking performance for people on a slackline.
Further section \textit{\nameref{5_2_dataModel}} covers how the data is structured and stored.
Currently each exercise has to be created by the developer such that the SLS can match and compare the movement performance of a trainee with the actual exercise. 
The workflow of constructing such exercises is described in section \textit{\nameref{5_3_movementRecognition}}.
%describes the recording and training of predefined exercises for the system. 
Lastly section \textit{\nameref{5_4_software}} explains the relationship between the Kinect SDK and Unity3D as game engine, as well as each application component based on a top-down workflow through the interface.

%data management, the interaction techniques, gesture integration, and real-time feedback.

%Lastly section \textit{\nameref{5_4_userInterface}} covers the design process of the application with scribbles, mock-ups, and the final interface.

\input{Chapter/5_System/1_SystemSetup}
\input{Chapter/5_System/2_DataModel}
\input{Chapter/5_System/3_MovementRecognition}
\input{Chapter/5_System/4_Frontend}

\begin{comment}
- Kinect used for tracking --> how Kinect tracks user - skeleton, infrared, own algorithm -> RW

- Technical feasibility in here?

- Recording of gestures --> Kinectstudio --> Making/Train gestures --> Visual gestures builder

- System architecture of system --> Unity3D, Kinect SDK, Kinectstudio, VGB --> kinect sdk free to use since version X

- Data management --> json file, default exercise json and each user has its own json file 

- Engagement with Kinect

- Interaction components (track hand joints, PHIZ, Constraints) --> different interactions tested (closing hand, V-sign, hover, pushing) --> not all good because of distance to Kinect --> In unity addon written for managing data --> create new users, load exercise in user, adjust jsons

- tier and exercises as level design --> locked and unlocking by successfully accomplishing exercise

- Integration VGB databases in Unity and how to track gestures in it --> gesturedetector, eventlistener

- Providing feedback properly --> confidence/progress of gestures in event listener, checklist (joint detection), 
--> user viewer --> how it works (making cloudy map regarding user position, drawing lines for skeletons)

- Summary screen --> feedback about prior or entire tier performance with time, confidence and attempts

- User interface design --> sketches, mock ups, development --> workflow figure
\end{comment}
\begin{comment}
\section{User Interface}\label{5_4_userInterface}
The user starts with an engagement gesture which is implemented as raising her hand over the head. After that a tutorial about interaction techniques of the system will be given. Now that she's confident with the system interaction she can select her profile in the user menu. This loads the profile which leads further to the level selection menu. In here she can select a level, whereas initially the first one is can be selected. Selecting a level leads to the exercise menu. In here she has to read initially the stage introduction to become a basic understanding about the exercises within. After reading this, it unlocks the first exercise. Selecting an exercise leads to the side selection, where the user has to choose the side she wants to train. This is followed by an introduction of the exercise, in which is explained how to perform it correctly. If the user is ready, she should stay in a starting position to be able to start the exercise execution. Then she find herself in the exercise execution scene. It provides indicators to correctly execute the exercise, like the time, repetitions, confidence and a checklist. After finishing with the exercise, a summary is shown which summarizes the user performance. Then she can return to the main menu or directly try the next exercise. At the end of each stage an overall summary gives an overview about all exercises with average performance parameters.

The user should be introduced to the stage. In here the purpose, goal, and helpful techniques should be given, such that the user becomes an overview about the exercises. At last a summary scene shows several performance parameter for the exercises in this stage.

\begin{figure}[htb]
	\centering
	\begin{minipage}[t]{1\linewidth}
		\centering
		\includegraphics[width=1\linewidth]{Pictures/5_1_UIWorkflow}
		\caption{Scenario workflow}
		\label{fig:scenarioWorkflow}
	\end{minipage}
\end{figure}
\end{comment}